{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Pegos Twitter Scraper (Top + Live, robust counts, always-save)\n",
    "# =====================================================\n",
    "import os, time, random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def safe_int(val: str):\n",
    "    \"\"\"Metin sayƒ±larƒ± (3.5K, 1M, vb.) g√ºvenli int'e √ßevirir.\"\"\"\n",
    "    if not val:\n",
    "        return 0\n",
    "    val = val.replace(',', '').replace('¬∑', '').strip()\n",
    "    try:\n",
    "        if val.endswith('B'):\n",
    "            return int(float(val[:-1]) * 1_000)\n",
    "        if val.endswith('M') or val.endswith('Mn'):\n",
    "            return int(float(val[:-1]) * 1_000_000)\n",
    "        return int(float(val))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def find_view_node(article):\n",
    "    \"\"\"Tweet view sayƒ±sƒ±nƒ± yakalamak i√ßin alternatif testler.\"\"\"\n",
    "    v = article.find(attrs={\"data-testid\": [\"viewCount\", \"views\"]})\n",
    "    if v: return v\n",
    "    v = article.find(\"span\", attrs={\"aria-label\": lambda s: s and \"views\" in s.lower()})\n",
    "    if v: return v\n",
    "    v = article.find(\"div\", attrs={\"aria-label\": lambda s: s and \"views\" in s.lower()})\n",
    "    return v\n",
    "\n",
    "def extract_tweet_url(article):\n",
    "    \"\"\"Tweet URL'ini √ßƒ±karƒ±r.\"\"\"\n",
    "    try:\n",
    "        ttag = article.find(\"time\")\n",
    "        if ttag:\n",
    "            a = ttag.find_parent(\"a\")\n",
    "            if a:\n",
    "                href = a.get(\"href\", \"\")\n",
    "                if href and \"/status/\" in href:\n",
    "                    return f\"https://x.com{href}\" if href.startswith(\"/\") else href\n",
    "        for a in article.find_all(\"a\", href=True):\n",
    "            href = a.get(\"href\", \"\")\n",
    "            if \"/status/\" in href:\n",
    "                return f\"https://x.com{href}\" if href.startswith(\"/\") else href\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ K√ºt√ºphaneler ve fonksiyonlar y√ºklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= ENV & PATHS =======================\n",
    "AUTH_TOKEN = os.getenv(\"AUTH_TOKEN\")\n",
    "CT0 = os.getenv(\"CT0\")\n",
    "if not AUTH_TOKEN or not CT0:\n",
    "    raise RuntimeError(\"‚ùå AUTH_TOKEN veya CT0 tanƒ±mlƒ± deƒüil (GitHub Secrets).\")\n",
    "\n",
    "TODAY = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "OUT_DIR = f\"/tmp/data/{TODAY}\"\n",
    "OUT_CSV = f\"{OUT_DIR}/pegos_output.csv\"\n",
    "LATEST_CSV = f\"{OUT_DIR}/latest.csv\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "print(\"üìÅ OUT_DIR:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= BROWSER =======================\n",
    "opts = Options()\n",
    "opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-gpu\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "opts.add_argument(\"--window-size=1920,1080\")\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "# Cookie login i≈ülemi\n",
    "driver.get(\"https://x.com\")\n",
    "time.sleep(3)\n",
    "driver.add_cookie({\"name\": \"auth_token\", \"value\": AUTH_TOKEN, \"domain\": \".x.com\"})\n",
    "driver.add_cookie({\"name\": \"ct0\", \"value\": CT0, \"domain\": \".x.com\"})\n",
    "driver.refresh()\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"‚úÖ Login ba≈üarƒ±lƒ±:\", driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= SCRAPE =======================\n",
    "KEYWORDS = [\"bitcoin\", \"blockchain\", \"cryptocurrency\"]\n",
    "MODES = [\"top\", \"live\"]  # √∂nce top, sonra live\n",
    "tweetArr = []\n",
    "\n",
    "for kw in KEYWORDS:\n",
    "    for mode in MODES:\n",
    "        print(f\"\\nüîé {kw} | mode={mode}\")\n",
    "        driver.get(f\"https://x.com/search?q={kw}&src=typed_query&f={mode}\")\n",
    "        time.sleep(6)\n",
    "\n",
    "        seen = set()\n",
    "        for _ in range(60):  # scroll sayƒ±sƒ± artƒ±rƒ±ldƒ±\n",
    "            driver.execute_script(\"window.scrollBy(0, 1200);\")\n",
    "            time.sleep(random.uniform(2.0, 3.2))\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            for art in soup.find_all(\"article\"):\n",
    "                try:\n",
    "                    text_tag = art.find(attrs={\"data-testid\": \"tweetText\"})\n",
    "                    if not text_tag:\n",
    "                        continue\n",
    "                    text = text_tag.get_text(\" \", strip=True)\n",
    "                    if len(text) < 8:\n",
    "                        continue\n",
    "\n",
    "                    ttag = art.find(\"time\")\n",
    "                    tstr = ttag[\"datetime\"] if ttag else None\n",
    "                    key = (text, tstr)\n",
    "                    if key in seen:\n",
    "                        continue\n",
    "                    seen.add(key)\n",
    "\n",
    "                    reply = art.find(attrs={\"data-testid\": [\"reply\", \"conversation\"]})\n",
    "                    retw = art.find(attrs={\"data-testid\": [\"retweet\", \"repost\"]})\n",
    "                    like = art.find(attrs={\"data-testid\": [\"like\", \"favorite\"]})\n",
    "                    view = find_view_node(art)\n",
    "                    tweet_url = extract_tweet_url(art)\n",
    "\n",
    "                    tweetArr.append({\n",
    "                        \"keyword\": kw,\n",
    "                        \"tweet\": text,\n",
    "                        \"time\": tstr,\n",
    "                        \"url\": tweet_url,\n",
    "                        \"comment\": safe_int(reply.get_text(strip=True) if reply else \"0\"),\n",
    "                        \"retweet\": safe_int(retw.get_text(strip=True) if retw else \"0\"),\n",
    "                        \"like\": safe_int(like.get_text(strip=True) if like else \"0\"),\n",
    "                        \"see_count\": safe_int(view.get_text(strip=True) if view else \"0\"),\n",
    "                    })\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        print(f\"‚úÖ {kw}/{mode}: {len(tweetArr)} tweet toplandƒ±.\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"üü¢ Toplam tweet sayƒ±sƒ±: {len(tweetArr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= SAVE =======================\n",
    "df = pd.DataFrame(tweetArr)\n",
    "\n",
    "if not df.empty:\n",
    "    df.drop_duplicates(subset=[\"tweet\", \"time\"], inplace=True)\n",
    "    sort_cols = [c for c in [\"like\", \"retweet\", \"comment\", \"see_count\"] if c in df.columns]\n",
    "    if sort_cols:\n",
    "        df.sort_values(by=sort_cols, ascending=False, inplace=True)\n",
    "else:\n",
    "    # bo≈ü olsa da kolon yapƒ±sƒ±nƒ± olu≈ütur\n",
    "    df = pd.DataFrame(columns=[\"keyword\", \"tweet\", \"time\", \"url\", \"comment\", \"retweet\", \"like\", \"see_count\"])\n",
    "\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "df.to_csv(LATEST_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"üíæ Kaydedildi: {OUT_CSV} ({len(df)} satƒ±r)\")\n",
    "print(f\"üíæ Kaydedildi: {LATEST_CSV} ({len(df)} satƒ±r)\")\n",
    "\n",
    "# ======================= HUGGING FACE UPLOAD =======================\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "HF_REPO = os.getenv(\"HF_REPO\", os.getenv(\"HF_REPO_ID\", \"Caner7/pegos-twitter-stream\"))  # HF_REPO_ID GitHub Secrets'tan geliyor, default: Caner7/pegos-twitter-stream\n",
    "\n",
    "if HF_TOKEN:\n",
    "    try:\n",
    "        login(token=HF_TOKEN)\n",
    "        print(f\"‚úÖ Hugging Face login ba≈üarƒ±lƒ±\")\n",
    "        \n",
    "        api = HfApi()\n",
    "        \n",
    "        # CSV dosyasƒ±nƒ± upload et\n",
    "        if os.path.exists(OUT_CSV):\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=OUT_CSV,\n",
    "                path_in_repo=f\"data/{TODAY}/pegos_output.csv\",\n",
    "                repo_id=HF_REPO,\n",
    "                repo_type=\"dataset\",\n",
    "                commit_message=f\"Update data for {TODAY}\"\n",
    "            )\n",
    "            print(f\"‚úÖ HF'ye y√ºklendi: {HF_REPO}/data/{TODAY}/pegos_output.csv\")\n",
    "        \n",
    "        if os.path.exists(LATEST_CSV):\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=LATEST_CSV,\n",
    "                path_in_repo=\"latest.csv\",\n",
    "                repo_id=HF_REPO,\n",
    "                repo_type=\"dataset\",\n",
    "                commit_message=f\"Update latest data for {TODAY}\"\n",
    "            )\n",
    "            print(f\"‚úÖ HF'ye y√ºklendi: {HF_REPO}/latest.csv\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Hugging Face upload hatasƒ±: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è HF_TOKEN tanƒ±mlƒ± deƒüil, Hugging Face'e y√ºkleme atlandƒ±.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
